import argparse
import os
import random
import sys
from pathlib import Path
from typing import List, Tuple


IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}


def _abs(p: Path) -> str:
    return str(p.resolve())


def find_dataset_root(preferred: str | None = None) -> Path:
    """Find a dataset root that contains images/ and labels/.

    Search order:
    - provided path (if any)
    - ./data/yolo
    - ../data/yolo
    - ./yolo_extracted
    """
    candidates = []
    if preferred:
        candidates.append(Path(preferred))
    candidates += [
        Path("data/yolo"),
        Path("../data/yolo"),
        Path("yolo_extracted"),
    ]
    for c in candidates:
        if (c / "images").exists() and (c / "labels").exists():
            return c.resolve()
    raise FileNotFoundError(
        "Dataset not found. Expected a folder with images/ and labels/. "
        "Tried: " + ", ".join(map(str, candidates))
    )


def collect_images(images_dir: Path) -> List[Path]:
    imgs = []
    for p in sorted(images_dir.glob("**/*")):
        if p.suffix.lower() in IMG_EXTS and p.is_file():
            imgs.append(p)
    return imgs


def ensure_splits(dataset_root: Path, split_dir: Path, val_ratio: float = 0.1, seed: int = 42) -> Tuple[Path, Path]:
    """Create train/val image lists (.txt) if a pre-made split is not found.

    Returns absolute paths to train.txt and val.txt.
    """
    images_root = dataset_root / "images"
    labels_root = dataset_root / "labels"

    # If COCO-like split directories exist, return them directly via list files for consistency
    split_train = images_root / "train"
    split_val = images_root / "val"
    if split_train.exists() and split_val.exists():
        train_imgs = collect_images(split_train)
        val_imgs = collect_images(split_val)
    else:
        # Flat images/labels; build a random split
        all_imgs = collect_images(images_root)
        # keep only those that have labels
        imgs = []
        for im in all_imgs:
            lab = labels_root / (im.stem + ".txt")
            if lab.exists():
                imgs.append(im)
        if not imgs:
            raise RuntimeError(f"No labeled images found under: {images_root}")
        random.Random(seed).shuffle(imgs)
        n_val = max(1, int(len(imgs) * val_ratio))
        val_imgs = imgs[:n_val]
        train_imgs = imgs[n_val:]
        if not train_imgs:
            # fall back to at least one train image
            train_imgs, val_imgs = imgs, imgs[: max(1, len(imgs)//10)]

    split_dir.mkdir(parents=True, exist_ok=True)
    train_list = split_dir / "train.txt"
    val_list = split_dir / "val.txt"
    train_list.write_text("\n".join(_abs(p) for p in train_imgs) + "\n", encoding="utf-8")
    val_list.write_text("\n".join(_abs(p) for p in val_imgs) + "\n", encoding="utf-8")
    return train_list.resolve(), val_list.resolve()


def write_pose_yaml(yaml_path: Path, train: Path, val: Path, class_name: str = "object", kpts: int = 1) -> Path:
    """Write a YOLO pose dataset YAML.

    Ultralytics expects:
    - train/val: dir paths or text files listing image paths
    - kpt_shape: [num_keypoints, 3]
    - names: list or dict of class names
    """
    yaml = f"""
# Auto-generated by src/detection/main.py
train: {train}
val: {val}
kpt_shape: [{kpts}, 3]
names: ["{class_name}"]
""".lstrip()
    yaml_path.parent.mkdir(parents=True, exist_ok=True)
    yaml_path.write_text(yaml, encoding="utf-8")
    return yaml_path.resolve()


def check_example_label(labels_root: Path, kpts: int = 1) -> None:
    """Light sanity check for label format: 1 class, bbox, and kpts*3 values.

    Each label line should be: cls cx cy w h x1 y1 v1 ... xK yK vK (normalized)
    """
    want_cols = 5 + 3 * kpts
    for f in sorted(labels_root.glob("**/*.txt")):
        txt = f.read_text(encoding="utf-8").strip()
        if not txt:
            continue
        line = txt.splitlines()[0].strip()
        parts = line.split()
        if len(parts) != want_cols:
            print(
                f"[warn] Label {f} has {len(parts)} columns, expected {want_cols} for {kpts} keypoint(s).",
                file=sys.stderr,
            )
        break


def do_train(args: argparse.Namespace) -> None:
    from ultralytics import YOLO

    data_root = find_dataset_root(args.data_root)
    check_example_label(data_root / "labels", kpts=1)

    # Ensure split file lists and dataset YAML
    splits_dir = Path(__file__).parent / "datasets" / "splits"
    train_list, val_list = ensure_splits(data_root, splits_dir, val_ratio=args.val_ratio, seed=args.seed)
    data_yaml = write_pose_yaml(
        yaml_path=Path(__file__).parent / "datasets" / "yolo_pose_data.yaml",
        train=train_list,
        val=val_list,
        class_name=args.class_name,
        kpts=1,
    )

    # Load model (pretrained pose) and train
    model = YOLO(args.model)

    # Strong augmentations for pose with 1 keypoint
    train_kwargs = dict(
        data=str(data_yaml),
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        device=args.device,
        workers=args.workers,
        optimizer="auto",
        # augmentations
        augment=True,
        mosaic=1.0,
        mixup=0.2,
        copy_paste=0.3,
        erasing=0.4,
        degrees=10.0,
        translate=0.10,
        scale=0.90,
        shear=5.0,
        perspective=0.001,
        flipud=0.5,
        fliplr=0.5,
        hsv_h=0.015,
        hsv_s=0.7,
        hsv_v=0.4,
        pretrain=True,
        project=str(Path("outputs") / "yolo_pose"),
        name=args.run_name,
    )

    # Some options may vary by ultralytics version; run with a safe subset if needed
    try:
        model.train(**train_kwargs)
    except TypeError as e:
        print(f"[warn] Retrying train with reduced aug args due to: {e}")
        reduced = {k: v for k, v in train_kwargs.items() if k in {
            "data","epochs","imgsz","batch","device","workers","optimizer","augment",
            "degrees","translate","scale","shear","perspective","flipud","fliplr",
            "hsv_h","hsv_s","hsv_v","project","name"}}
        model.train(**reduced)


def do_predict(args: argparse.Namespace) -> None:
    from ultralytics import YOLO

    model = YOLO(args.weights)
    results = model.predict(
        source=args.source,
        imgsz=args.imgsz,
        conf=args.conf,
        iou=args.iou,
        device=args.device,
        save=args.save,
        project=str(Path("outputs") / "yolo_pose"),
        name=args.run_name if args.save else None,
    )
    # Example of accessing keypoints
    for i, r in enumerate(results):
        if getattr(r, "keypoints", None) is not None:
            print(f"[info] Image {i}: keypoints shape = {getattr(r.keypoints, 'shape', None)}")
            print(f"[info] First 5 keypoints (xy): {getattr(r.keypoints, 'xy', None)[:,:5] if hasattr(r.keypoints, 'xy') else None}")


def do_export(args: argparse.Namespace) -> None:
    from ultralytics import YOLO

    model = YOLO(args.weights)
    out = model.export(format=args.format, dynamic=args.dynamic, simplify=args.simplify, opset=args.opset)
    print(f"[info] Exported to: {out}")


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        description="Train/Predict/Export YOLO Pose on a custom dataset with 1 keypoint",
    )
    sub = p.add_subparsers(dest="cmd", required=True)

    # Train
    pt = sub.add_parser("train", help="Train a YOLO pose model")
    pt.add_argument("--data-root", default=None, help="Dataset root containing images/ and labels/. Defaults to data/yolo if present")
    pt.add_argument("--model", default="yolo11n-pose.pt", help="Base model weights or YAML")
    pt.add_argument("--epochs", type=int, default=100)
    pt.add_argument("--imgsz", type=int, default=640)
    pt.add_argument("--batch", type=int, default=16)
    pt.add_argument("--device", default=None, help="CUDA device like '0' or '0,1' or 'cpu'")
    pt.add_argument("--workers", type=int, default=8)
    pt.add_argument("--val-ratio", type=float, default=0.1, dest="val_ratio")
    pt.add_argument("--seed", type=int, default=42)
    pt.add_argument("--class-name", default="object")
    pt.add_argument("--run-name", default="train")
    pt.set_defaults(func=do_train)

    # Predict
    pp = sub.add_parser("predict", help="Run inference with a trained pose model")
    pp.add_argument("--weights", default="outputs/yolo_pose/train/weights/best.pt")
    pp.add_argument("--source", default="data/yolo/images")
    pp.add_argument("--imgsz", type=int, default=640)
    pp.add_argument("--conf", type=float, default=0.25)
    pp.add_argument("--iou", type=float, default=0.45)
    pp.add_argument("--device", default=None)
    pp.add_argument("--save", action="store_true")
    pp.add_argument("--run-name", default="predict")
    pp.set_defaults(func=do_predict)

    # Export
    pe = sub.add_parser("export", help="Export a trained model to ONNX, etc.")
    pe.add_argument("--weights", default="outputs/yolo_pose/train/weights/best.pt")
    pe.add_argument("--format", default="onnx", choices=["onnx", "torchscript", "engine", "openvino", "coreml", "saved_model"])
    pe.add_argument("--dynamic", action="store_true")
    pe.add_argument("--simplify", action="store_true")
    pe.add_argument("--opset", type=int, default=None)
    pe.set_defaults(func=do_export)

    return p


def main(argv: List[str] | None = None) -> None:
    parser = build_parser()
    args = parser.parse_args(argv)
    args.func(args)


if __name__ == "__main__":
    main()
