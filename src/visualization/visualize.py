import os
import sys
import argparse
import numpy as np
from src.colmap_utils import read_write_model


def export_scene_to_obj(output_obj_path, 
                        point_cloud_vertices, point_cloud_colors, point_cube_size,
                        camera_frustum_vertices, camera_frustum_colors, num_cameras):
    """Exports 3D points (as small cubes) and camera frustums to an OBJ file."""
    os.makedirs(os.path.dirname(output_obj_path), exist_ok=True)
        
    with open(output_obj_path, 'w') as f:
        num_points = len(point_cloud_vertices) if point_cloud_vertices else 0
        f.write("# OBJ file generated by visualize.py\n")
        f.write(f"# Exporting {num_points} 3D points (as cubes) and {num_cameras} camera frustums.\n\n")

        current_vertex_idx = 1

        # Write Point Cloud Cubes
        if point_cloud_vertices and point_cube_size > 0:
            f.write("# Point Cloud Cubes\n")
            s = point_cube_size / 2.0

            for i in range(len(point_cloud_vertices)):
                center = point_cloud_vertices[i]
                color = point_cloud_colors[i] if i < len(point_cloud_colors) else np.array([128, 128, 128], dtype=np.uint8)
                r_norm, g_norm, b_norm = color[0]/255.0, color[1]/255.0, color[2]/255.0

                verts = [
                    center + np.array([-s, -s, -s]), center + np.array([s, -s, -s]),
                    center + np.array([s, s, -s]),  center + np.array([-s, s, -s]),
                    center + np.array([-s, -s, s]), center + np.array([s, -s, s]),
                    center + np.array([s, s, s]),   center + np.array([-s, s, s])
                ]
                
                f.write(f"\ng o point_cube_{i+1}\n")
                for v_coord in verts:
                    f.write(f"v {v_coord[0]:.6f} {v_coord[1]:.6f} {v_coord[2]:.6f} {r_norm:.4f} {g_norm:.4f} {b_norm:.4f}\n")
                
                # Front face
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+1} {current_vertex_idx+2}\n")
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+2} {current_vertex_idx+3}\n")
                # Back face
                f.write(f"f {current_vertex_idx+4} {current_vertex_idx+5} {current_vertex_idx+6}\n")
                f.write(f"f {current_vertex_idx+4} {current_vertex_idx+6} {current_vertex_idx+7}\n")
                # Top face
                f.write(f"f {current_vertex_idx+3} {current_vertex_idx+2} {current_vertex_idx+6}\n")
                f.write(f"f {current_vertex_idx+3} {current_vertex_idx+6} {current_vertex_idx+7}\n")
                # Bottom face
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+1} {current_vertex_idx+5}\n")
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+5} {current_vertex_idx+4}\n")
                # Right face
                f.write(f"f {current_vertex_idx+1} {current_vertex_idx+5} {current_vertex_idx+6}\n")
                f.write(f"f {current_vertex_idx+1} {current_vertex_idx+6} {current_vertex_idx+2}\n")
                # Left face
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+4} {current_vertex_idx+7}\n")
                f.write(f"f {current_vertex_idx+0} {current_vertex_idx+7} {current_vertex_idx+3}\n")
                
                current_vertex_idx += 8
            f.write("\n")

        # Write Camera Frustum Vertices
        camera_frustum_start_idx = current_vertex_idx
        if camera_frustum_vertices:
            f.write("# Camera Frustum Vertices (x y z r g b)\n")
            for i in range(len(camera_frustum_vertices)):
                v = camera_frustum_vertices[i]
                c = camera_frustum_colors[i] if i < len(camera_frustum_colors) else np.array([0,255,0], dtype=np.uint8)
                r_norm, g_norm, b_norm = c[0]/255.0, c[1]/255.0, c[2]/255.0
                f.write(f"v {v[0]:.6f} {v[1]:.6f} {v[2]:.6f} {r_norm:.4f} {g_norm:.4f} {b_norm:.4f}\n")
                current_vertex_idx += 1
            f.write("\n")

        # Write Camera Faces
        if num_cameras > 0 and camera_frustum_vertices:
            f.write("# Camera faces\n")
            for i in range(num_cameras):
                apex_idx = camera_frustum_start_idx + (i * 5) + 0
                b1_idx   = camera_frustum_start_idx + (i * 5) + 1
                b2_idx   = camera_frustum_start_idx + (i * 5) + 2
                b3_idx   = camera_frustum_start_idx + (i * 5) + 3
                b4_idx   = camera_frustum_start_idx + (i * 5) + 4

                f.write(f"\ng camera_frustum_{i+1}\n")
                f.write(f"f {apex_idx} {b1_idx} {b2_idx}\n")
                f.write(f"f {apex_idx} {b2_idx} {b3_idx}\n")
                f.write(f"f {apex_idx} {b3_idx} {b4_idx}\n")
                f.write(f"f {apex_idx} {b4_idx} {b1_idx}\n")
                f.write(f"f {b1_idx} {b3_idx} {b2_idx}\n")
                f.write(f"f {b1_idx} {b4_idx} {b3_idx}\n")

    print(f"Successfully wrote {num_points} points (as cubes) and {num_cameras} camera frustums to {output_obj_path}")


def find_all_reconstructions(base_path):
    """Find all reconstructions in sparse folder."""
    sparse_path = os.path.join(base_path, "sparse")
    if not os.path.exists(sparse_path):
        return []
    
    # Find all numbered folders in sparse
    reconstruction_dirs = []
    for item in os.listdir(sparse_path):
        item_path = os.path.join(sparse_path, item)
        if os.path.isdir(item_path) and item.isdigit():
            reconstruction_dirs.append((int(item), item_path))
    
    # Return all paths sorted by number
    reconstruction_dirs.sort(key=lambda x: x[0])
    return reconstruction_dirs


def main():
    parser = argparse.ArgumentParser(description="Visualize COLMAP reconstruction as OBJ file")
    parser.add_argument("input_path", help="Path to COLMAP output directory or sparse model directory")
    parser.add_argument("--output", help="Output OBJ file path (default: auto-generated)")
    parser.add_argument("--min_track_len", type=int, default=3, help="Minimum track length for points (default: 3)")
    parser.add_argument("--max_reproj_error", type=float, default=2.0, help="Maximum reprojection error (default: 2.0)")
    parser.add_argument("--camera_scale", type=float, default=0.2, help="Camera frustum scale (default: 0.2)")
    parser.add_argument("--point_cube_size", type=float, default=0.05, help="Point cube size (default: 0.05)")
    parser.add_argument("--outlier_percentile", type=float, default=95.0, help="Outlier distance percentile cutoff (default: 95.0)")
    
    args = parser.parse_args()
    
    # Process single reconstruction or multiple reconstructions
    reconstructions_to_process = []
    
    if os.path.exists(os.path.join(args.input_path, "cameras.bin")):
        # Direct sparse model directory
        sparse_num = os.path.basename(os.path.dirname(args.input_path))
        reconstructions_to_process.append((int(sparse_num) if sparse_num.isdigit() else 0, args.input_path))
        base_output_dir = os.path.dirname(os.path.dirname(args.input_path))
    else:
        # Find all reconstructions in sparse folder
        reconstructions_to_process = find_all_reconstructions(args.input_path)
        if not reconstructions_to_process:
            print(f"Error: No reconstruction found in {args.input_path}/sparse/")
            sys.exit(1)
        base_output_dir = args.input_path
    
    # Process each reconstruction
    for sparse_num, input_model_dir in reconstructions_to_process:
        print(f"\n=== Processing sparse/{sparse_num} ===")
        print(f"Reading COLMAP model from: {input_model_dir}")
        
        try:
            cameras, images, points3D_data = read_write_model.read_model(path=input_model_dir, ext=".bin")
        except Exception as e:
            print(f"Error reading model from {input_model_dir}: {e}")
            continue
            
        print(f"Found {len(cameras)} cameras, {len(images)} images, and {len(points3D_data)} 3D points.")

        # Filter 3D points
        filtered_points_xyz = []
        filtered_points_colors = []
        default_color = np.array([128, 128, 128], dtype=np.uint8)

        for point_id, point3D in points3D_data.items():
            if len(point3D.image_ids) >= args.min_track_len and point3D.error <= args.max_reproj_error:
                filtered_points_xyz.append(point3D.xyz)
                filtered_points_colors.append(point3D.rgb if hasattr(point3D, 'rgb') else default_color)
        
        print(f"After filtering: {len(filtered_points_xyz)} points remaining.")

        # Outlier filtering
        output_points_vertices = []
        output_points_colors = []

        if filtered_points_xyz and 0 < args.outlier_percentile < 100.0:
            points_np = np.array(filtered_points_xyz)
            centroid = np.mean(points_np, axis=0)
            distances = np.linalg.norm(points_np - centroid, axis=1)
            distance_threshold = np.percentile(distances, args.outlier_percentile)
            
            for i in range(len(filtered_points_xyz)):
                if distances[i] <= distance_threshold:
                    output_points_vertices.append(filtered_points_xyz[i])
                    output_points_colors.append(filtered_points_colors[i])
            print(f"After outlier filtering: {len(output_points_vertices)} points remaining.")
        else:
            output_points_vertices = filtered_points_xyz
            output_points_colors = filtered_points_colors

        # Process cameras
        all_camera_frustum_vertices = []
        all_camera_frustum_colors = []
        camera_color = np.array([0, 255, 0], dtype=np.uint8)
        
        for image_id, image in images.items():
            R = read_write_model.qvec2rotmat(image.qvec)
            t = image.tvec
            cam_center_world = -R.T @ t
            s = args.camera_scale
            z_offset = 1.5 * s
            
            # Define frustum vertices in camera space
            camera_points_cam = [
                np.array([0, 0, 0]),           # apex
                np.array([s, -s, z_offset]),   # base corners
                np.array([-s, -s, z_offset]),
                np.array([-s, s, z_offset]),
                np.array([s, s, z_offset])
            ]
            
            # Transform to world space
            for p_cam in camera_points_cam:
                p_world = R.T @ p_cam + cam_center_world
                all_camera_frustum_vertices.append(p_world)
                all_camera_frustum_colors.append(camera_color)
        
        print(f"Processed {len(images)} camera poses.")

        # Determine output path
        if args.output and len(reconstructions_to_process) == 1:
            output_obj_path = args.output
        else:
            visualization_dir = os.path.join(base_output_dir, "visualization")
            os.makedirs(visualization_dir, exist_ok=True)
            # Use the folder name and sparse number for the OBJ file
            folder_name = os.path.basename(os.path.normpath(base_output_dir))
            output_obj_path = os.path.join(visualization_dir, f"{folder_name}_sparse{sparse_num}.obj")

        # Export to OBJ
        export_scene_to_obj(output_obj_path, 
                            output_points_vertices, output_points_colors, args.point_cube_size,
                            all_camera_frustum_vertices, all_camera_frustum_colors, 
                            len(images))


if __name__ == "__main__":
    main()